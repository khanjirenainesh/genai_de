{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "from io import StringIO\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded successfully\n"
     ]
    }
   ],
   "source": [
    "required_vars = {\n",
    "    \"AZURE_OPENAI_ENDPOINT\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"AZURE_OPENAI_4o_DEPLOYMENT_NAME\": os.environ.get(\"AZURE_OPENAI_4o_DEPLOYMENT_NAME\"),\n",
    "    \"AZURE_OPENAI_API_VERSION\": os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    \"AZURE_OPENAI_API_KEY\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"SNOWFLAKE_USER\": os.environ.get(\"SNOWFLAKE_USER\"),\n",
    "    \"SNOWFLAKE_PASSWORD\": os.environ.get(\"SNOWFLAKE_PASSWORD\"),\n",
    "    \"SNOWFLAKE_ACCOUNT\": os.environ.get(\"SNOWFLAKE_ACCOUNT\"),\n",
    "    \"SNOWFLAKE_WAREHOUSE\": os.environ.get(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "    \"SNOWFLAKE_DATABASE\": os.environ.get(\"SNOWFLAKE_DATABASE\"),\n",
    "    \"SNOWFLAKE_SCHEMA\": os.environ.get(\"SNOWFLAKE_SCHEMA\")\n",
    "}\n",
    "\n",
    "missing_vars = [key for key, value in required_vars.items() if value is None]\n",
    "if missing_vars:\n",
    "    raise ValueError(f\"Missing required environment variables: {', '.join(missing_vars)}\")\n",
    "print(\"Environment variables loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Snowflake\n"
     ]
    }
   ],
   "source": [
    "connection_string = (\n",
    "    f\"snowflake://{required_vars['SNOWFLAKE_USER']}:\"\n",
    "    f\"{required_vars['SNOWFLAKE_PASSWORD']}@\"\n",
    "    f\"{required_vars['SNOWFLAKE_ACCOUNT']}/\"\n",
    "    f\"{required_vars['SNOWFLAKE_DATABASE']}/\"\n",
    "    f\"{required_vars['SNOWFLAKE_SCHEMA']}?warehouse=\"\n",
    "    f\"{required_vars['SNOWFLAKE_WAREHOUSE']}\"\n",
    ")\n",
    "\n",
    "engine = create_engine(connection_string)\n",
    "print(\"Connected to Snowflake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available tables: ['PATIENT_ADMISSIONS' 'SALES_DATA' 'ADDRESSES']\n"
     ]
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT \n",
    "        c.TABLE_NAME, c.COLUMN_NAME, c.DATA_TYPE, c.IS_NULLABLE, c.CHARACTER_MAXIMUM_LENGTH\n",
    "    FROM {required_vars['SNOWFLAKE_DATABASE']}.INFORMATION_SCHEMA.COLUMNS c\n",
    "    JOIN {required_vars['SNOWFLAKE_DATABASE']}.INFORMATION_SCHEMA.TABLES t \n",
    "        ON c.TABLE_NAME = t.TABLE_NAME\n",
    "    WHERE t.TABLE_TYPE = 'BASE TABLE' \n",
    "    AND c.TABLE_SCHEMA = '{required_vars['SNOWFLAKE_SCHEMA']}'\n",
    "\"\"\"\n",
    "\n",
    "conn = engine.connect()\n",
    "metadata = pd.read_sql(query, conn.connection)\n",
    "metadata.columns = [col.lower() for col in metadata.columns]\n",
    "\n",
    "print(\"\\nAvailable tables:\", metadata['table_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATIENT_ADMISSIONS\n",
      "SALES_DATA\n",
      "ADDRESSES\n"
     ]
    }
   ],
   "source": [
    "for i in metadata['table_name'].unique():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieving data from table: PATIENT_ADMISSIONS\n",
      "Retrieved 55500 rows\n"
     ]
    }
   ],
   "source": [
    "table_name = metadata['table_name'].unique()[0]  # Get first table only\n",
    "\n",
    "print(f\"\\nRetrieving data from table: {table_name}\")\n",
    "\n",
    "query = f\"SELECT * FROM {required_vars['SNOWFLAKE_DATABASE']}.{required_vars['SNOWFLAKE_SCHEMA']}.{table_name}\"\n",
    "conn = engine.connect()\n",
    "df = pd.read_sql(query, conn.connection)\n",
    "print(f\"Retrieved {len(df)} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if you want to load all tables >>\n",
    "# for i in metadata['table_name'].unique():\n",
    "#     print(i)\n",
    "#     print(f\"\\nRetrieving data from table: {table_name}\")\n",
    "\n",
    "#     query = f\"SELECT * FROM {required_vars['SNOWFLAKE_DATABASE']}.{required_vars['SNOWFLAKE_SCHEMA']}.{table_name}\"\n",
    "#     df = pd.read_sql(query, engine)\n",
    "#     print(f\"Retrieved {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampled 1000 rows from original 55500 rows\n",
      "\n",
      "Sample of data:\n",
      "                      NAME  AGE  GENDER BLOOD_TYPE MEDICAL_CONDITION  \\\n",
      "31641  mIchAEl thOrnTon mD   57    Male         O+          Diabetes   \n",
      "9246    mattheW HUTcHiNsOn   51  Female         A+          Diabetes   \n",
      "1583           RoNald paRK   20    Male         A+            Asthma   \n",
      "36506          Jeff BroOkS   74  Female         B+           Obesity   \n",
      "11259       TAnya THoMPsOn   56    Male        AB-           Obesity   \n",
      "\n",
      "      DATE_OF_ADMISSION           DOCTOR                         HOSPITAL  \\\n",
      "31641        2023-09-15     Jason Hanson                     Thornton-Roy   \n",
      "9246         2023-10-07   Jesse Gonzalez                  Wilkerson-Lewis   \n",
      "1583         2019-09-09  Sarah Hernandez                     Brown-Hughes   \n",
      "36506        2020-09-14    Cathy Sanchez       Wilson, Alexander Wolf and   \n",
      "11259        2023-02-01        Nancy Lee  Winters, Blackburn Chandler and   \n",
      "\n",
      "      INSURANCE_PROVIDER  BILLING_AMOUNT  ROOM_NUMBER ADMISSION_TYPE  \\\n",
      "31641           Medicare         3616.90          339       Elective   \n",
      "9246               Aetna        36970.08          372      Emergency   \n",
      "1583          Blue Cross        44393.00          148       Elective   \n",
      "36506              Aetna        27554.92          135      Emergency   \n",
      "11259              Aetna        27466.32          284      Emergency   \n",
      "\n",
      "      DISCHARGE_DATE   MEDICATION  TEST_RESULTS  \n",
      "31641     2023-10-02      Aspirin  Inconclusive  \n",
      "9246      2023-10-14   Penicillin      Abnormal  \n",
      "1583      2019-10-08   Penicillin  Inconclusive  \n",
      "36506     2020-09-21    Ibuprofen      Abnormal  \n",
      "11259     2023-02-07  Paracetamol  Inconclusive  \n"
     ]
    }
   ],
   "source": [
    "sample_size = min(int(len(df) * 0.05), 1000)\n",
    "sampled_df = df.sample(n=sample_size, random_state=42)\n",
    "print(f\"\\nSampled {len(sampled_df)} rows from original {len(df)} rows\")\n",
    "print(\"\\nSample of data:\")\n",
    "print(sampled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AzureChatOpenAI(\n",
    "    azure_endpoint=required_vars[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=required_vars[\"AZURE_OPENAI_4o_DEPLOYMENT_NAME\"],\n",
    "    openai_api_version=required_vars[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    openai_api_key=required_vars[\"AZURE_OPENAI_API_KEY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_str = StringIO()\n",
    "sampled_df.head(100).to_csv(data_str, index=False)\n",
    "data_str = data_str.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_metadata = metadata[metadata['table_name'] == table_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data quality insights...\n",
      "\n",
      "Data quality insights generated\n",
      "data_quality_issues : [{'issue': 'Inconsistent Text Casing', 'details': \"The 'NAME', 'DOCTOR', 'HOSPITAL', and 'MEDICATION' fields have inconsistent casing (e.g., 'mIchAEl thOrnTon mD', 'mattheW HUTcHiNsOn').\"}, {'issue': 'Gender Mismatch', 'details': \"There are records where the 'NAME' suggests a different gender than what is recorded (e.g., 'Jeff BroOkS' with gender 'Female').\"}, {'issue': 'Future Date Anomalies', 'details': \"Some 'DATE_OF_ADMISSION' entries are in the future (e.g., '2024-04-17').\"}]\n",
      "recommended_solutions : [{'solution': 'Standardize Text Casing', 'details': 'Ensure all textual fields follow a consistent casing format, such as title case.'}, {'solution': 'Validate Gender', 'details': \"Implement checks to verify that the 'GENDER' field matches the expected gender based on 'NAME'.\"}, {'solution': 'Date Validation', 'details': \"Enforce constraints to prevent future dates in the 'DATE_OF_ADMISSION' field unless explicitly required.\"}]\n",
      "sql_queries : [{'query_name': 'Standardize Name Casing', 'sql': 'UPDATE table_name SET NAME = INITCAP(NAME);'}, {'query_name': 'Identify Gender Mismatches', 'sql': \"SELECT NAME, GENDER FROM table_name WHERE GENDER NOT IN ('Male', 'Female');\"}, {'query_name': 'Check Future Admission Dates', 'sql': 'SELECT * FROM table_name WHERE DATE_OF_ADMISSION > CURRENT_DATE;'}]\n",
      "sensitive_data_recommendations : [{'field': 'NAME', 'recommendation': 'Consider hashing or encrypting patient names to maintain privacy.'}, {'field': 'INSURANCE_PROVIDER', 'recommendation': 'Limit access to insurance provider data to authorized personnel only.'}, {'field': 'MEDICAL_CONDITION', 'recommendation': 'Implement data masking techniques for this field in non-authorized access scenarios.'}]\n"
     ]
    }
   ],
   "source": [
    "data_quality_prompt = f\"\"\"\n",
    "Analyze this data sample ({len(sampled_df)} total rows, showing first 100):\n",
    "\n",
    "Table Data:\n",
    "{data_str}\n",
    "\n",
    "Table Metadata:\n",
    "{table_metadata[['column_name', 'data_type']].to_string()}\n",
    "\n",
    "Please provide a comprehensive analysis focusing on:\n",
    "1. Data quality issues\n",
    "2. Pattern anomalies\n",
    "3. Potential sensitive data fields\n",
    "4. Suggested improvements\n",
    "\n",
    "Format your response as JSON with these keys:\n",
    "- data_quality_issues\n",
    "- recommended_solutions\n",
    "- sql_queries\n",
    "- sensitive_data_recommendations\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_quality = \"\"\"You are a specialized data analyst expert in Snowflake databases.\n",
    "Analyze the provided data sample focusing on data quality and patterns.\n",
    "Keep responses focused and brief. Ensure JSON format.\"\"\"\n",
    "\n",
    "messages_quality = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt_quality},\n",
    "    {\"role\": \"user\", \"content\": data_quality_prompt}\n",
    "]\n",
    "\n",
    "print(\"Generating data quality insights...\")\n",
    "quality_response = model.invoke(messages_quality).content.replace(\"plaintext\", \"\").replace(\"json\", \"\").replace(\"```\", \"\").strip()\n",
    "print(\"\\nData quality insights generated\")\n",
    "# print(quality_response)\n",
    "quality_response_json = json.loads(quality_response)\n",
    "print( \"data_quality_issues : \" + str(quality_response_json.get(\"data_quality_issues\",\"\")))\n",
    "print( \"recommended_solutions : \" + str(quality_response_json.get(\"recommended_solutions\",\"\")))\n",
    "print( \"sql_queries : \" + str(quality_response_json.get(\"sql_queries\",\"\")))\n",
    "print( \"sensitive_data_recommendations : \" + str(quality_response_json.get(\"sensitive_data_recommendations\",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating semantic analysis...\n",
      "Semantic analysis generated\n",
      "### Columns with Issues:\n",
      "\n",
      "#### 1. NAME\n",
      "- **Current Semantic Meaning:** This column should contain the full name of the patient.\n",
      "- **Data Type Issues:** None with the data type, but there are semantic issues with inconsistent use of capitalization and inclusion of titles.\n",
      "- **Example of Inconsistent Values:**\n",
      "  - \"mIchAEl thOrnTon mD\" (includes title \"MD\")\n",
      "  - \"mrs. sabrInA mOrEnO\" (includes title \"mrs.\")\n",
      "  - \"MR. keIth NelSon\" (includes title \"MR.\")\n",
      "- **Recommended Improvements:** Standardize the capitalization of names and remove titles for consistency. Consider using a separate column for titles if necessary.\n",
      "\n",
      "#### 2. GENDER\n",
      "- **Current Semantic Meaning:** This column should indicate the gender of the patient.\n",
      "- **Data Type Issues:** None with the data type, but there are semantic issues with gender values not matching typical expectations.\n",
      "- **Example of Inconsistent Values:**\n",
      "  - \"Jeff BroOkS,74,Female\" (typically, Jeff is a male name)\n",
      "  - \"TAnya THoMPsOn,56,Male\" (typically, Tanya is a female name)\n",
      "- **Recommended Improvements:** Verify and correct gender entries where there is a mismatch with typical name gender associations. If necessary, cross-reference with other patient records or documentation for accuracy.\n",
      "\n",
      "#### 3. DOCTOR\n",
      "- **Current Semantic Meaning:** This column should contain the name of the attending doctor.\n",
      "- **Data Type Issues:** None with the data type, but there are semantic issues with inconsistent formats and inclusion of titles.\n",
      "- **Example of Inconsistent Values:**\n",
      "  - \"Blake Flores MD\" (includes title \"MD\")\n",
      "  - \"Mrs. Shannon Thompson DDS\" (includes title \"DDS\")\n",
      "- **Recommended Improvements:** Standardize the format by removing titles for consistency. Consider using a separate column for titles if necessary.\n",
      "\n",
      "#### 4. DISCHARGE_DATE\n",
      "- **Current Semantic Meaning:** This column should contain the date the patient was discharged.\n",
      "- **Data Type Issues:** No issues with the data type, but there are future dates which may not be valid for a discharge date.\n",
      "- **Example of Inconsistent Values:**\n",
      "  - \"JuAN BaiLEY,38,Male,B-,Diabetes,2024-04-17\" with discharge date \"2024-05-12\"\n",
      "- **Recommended Improvements:** Verify future dates to ensure they are intended or correct them if they are errors.\n",
      "\n",
      "#### 5. HOSPITAL\n",
      "- **Current Semantic Meaning:** This column should contain the name of the hospital where the patient was admitted.\n",
      "- **Data Type Issues:** None with the data type, but there are semantic issues with inconsistent formats such as inclusion of commas and different naming conventions.\n",
      "- **Example of Inconsistent Values:**\n",
      "  - \"Wilson, Alexander Wolf and\"\n",
      "  - \"LLC Grimes\"\n",
      "  - \"Group Mayer\"\n",
      "- **Recommended Improvements:** Standardize naming conventions for hospitals to ensure consistency and clarity. Consider removing organizational structures like \"LLC\" or \"Group\" if not necessary.\n",
      "\n",
      "#### 6. INSURANCE_PROVIDER\n",
      "- **Current Semantic Meaning:** This column should contain the name of the insurance provider.\n",
      "- **Data Type Issues:** None with the data type, but inconsistent naming formats and inclusion of organizational structures like \"Inc\" or \"LLC\" may cause confusion.\n",
      "- **Example of Inconsistent Values:**\n",
      "  - \"Inc Shaw\"\n",
      "  - \"LLC George\"\n",
      "- **Recommended Improvements:** Standardize naming conventions for insurance providers, potentially removing unnecessary organizational structures for clarity.\n",
      "\n",
      "By addressing these semantic inconsistencies, the data quality and usability of the `PATIENT_ADMISSIONS` table can be significantly improved.\n"
     ]
    }
   ],
   "source": [
    "semantic_prompt = f\"\"\"\n",
    "Analysis for Snowflake table '{table_name}':\n",
    "Consider Snowflake-specific data types and variant/array columns.\n",
    "\n",
    "Sample data:\n",
    "{data_str}\n",
    "\n",
    "Metadata:\n",
    "{table_metadata.to_string()}\n",
    "\n",
    "Analyze each column focusing on:\n",
    "1. Scan through the records of each column to check if the data aligns with its semantic meaning.\n",
    "2. Highlight errors ONLY IF the semantic meaning does not align with the column name.\n",
    "3. Skip the columns where the semantic meaning and the data it holds is valid.\n",
    "4. Check for Snowflake-specific data type optimizations.\n",
    "5. ONLY provide column names and their issues.\n",
    "6. Go through all the columns and all the tables.\n",
    "7. Ensure the format intact.\n",
    "8. Please provide details of columns which has issues.\n",
    "9. Provide all the inconsistencies present with their values.\n",
    "10. In example provide all the discrepancy values.\n",
    "\n",
    "Format your response focusing only on columns with issues, providing:\n",
    "1. Column name\n",
    "2. Current semantic meaning\n",
    "3. Data type issues\n",
    "4. Example of inconsistent values\n",
    "5. Recommended improvements\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_semantic = \"\"\"You are a data semantic analysis expert.\n",
    "Focus on semantic meaning of columns and data type consistency.\n",
    "Provide clear, specific examples of any misalignments found.\n",
    "Keep analysis focused on columns with actual issues.\"\"\"\n",
    "\n",
    "messages_semantic = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt_semantic},\n",
    "    {\"role\": \"user\", \"content\": semantic_prompt}\n",
    "]\n",
    "\n",
    "print(\"\\nGenerating semantic analysis...\")\n",
    "semantic_response = model.invoke(messages_semantic).content\n",
    "print(\"Semantic analysis generated\")\n",
    "print(semantic_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating semantic analysis...\n",
      "Semantic analysis generated\n"
     ]
    }
   ],
   "source": [
    "semantic_prompt = f\"\"\"\n",
    "Analysis for Snowflake table '{table_name}':\n",
    "Consider Snowflake-specific data types and variant/array columns.\n",
    "\n",
    "Sample data:\n",
    "{data_str}\n",
    "\n",
    "Metadata:\n",
    "{table_metadata.to_string()}\n",
    "\n",
    "Analyze each column focusing on:\n",
    "1. Scan through the records of each column to check if the data aligns with its semantic meaning.\n",
    "2. Highlight errors ONLY IF the semantic meaning does not align with the column name.\n",
    "3. Skip the columns where the semantic meaning and the data it holds is valid.\n",
    "4. Check for Snowflake-specific data type optimizations.\n",
    "5. ONLY provide column names and their issues.\n",
    "6. Go through all the columns and all the tables.\n",
    "7. Ensure the format intact.\n",
    "8. Please provide details of columns which has issues.\n",
    "9. Provide all the inconsistencies present with their values.\n",
    "10. In example provide all the discrepancy values.\n",
    "\n",
    "Format your response focusing only on columns with issues, providing:\n",
    "1. Column name\n",
    "2. Current semantic meaning\n",
    "3. Data type issues\n",
    "4. Example of inconsistent values\n",
    "5. Recommended improvements\n",
    "\"\"\"\n",
    "\n",
    "system_prompt_semantic = \"\"\"You are a data semantic analysis expert.\n",
    "Focus on semantic meaning of columns and data type consistency.\n",
    "Provide clear, specific examples of any misalignments found.\n",
    "Keep analysis focused on columns with actual issues.\"\"\"\n",
    "\n",
    "messages_semantic = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt_semantic},\n",
    "    {\"role\": \"user\", \"content\": semantic_prompt}\n",
    "]\n",
    "\n",
    "print(\"\\nGenerating semantic analysis...\")\n",
    "semantic_response = model.invoke(messages_semantic)\n",
    "print(\"Semantic analysis generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to analysis_results_20250217_131953.json\n"
     ]
    }
   ],
   "source": [
    "# timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "# results = {\n",
    "#     'table_name': table_name,\n",
    "#     'timestamp': timestamp,\n",
    "#     'data_quality_analysis': quality_response.content,\n",
    "#     'semantic_analysis': semantic_response.content\n",
    "# }\n",
    "\n",
    "# # Save to JSON file\n",
    "# with open(f'analysis_results_{timestamp}.json', 'w') as f:\n",
    "#     json.dump(results, f, indent=2)\n",
    "# print(f\"\\nResults saved to analysis_results_{timestamp}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results saved to analysis_results_20250217_132252.csv\n",
      "\n",
      "Preview of CSV content:\n",
      "   table_name        timestamp  \\\n",
      "0  SALES_DATA  20250217_132252   \n",
      "\n",
      "                               data_quality_analysis  \\\n",
      "0  ```json\\n{\\n  \"data_quality_issues\": {\\n    \"i...   \n",
      "\n",
      "                                   semantic_analysis  \n",
      "0  1. **CATEGROY_2**\\n   - **Current semantic mea...  \n"
     ]
    }
   ],
   "source": [
    "### json to csv >>>>>>>>>>>>\n",
    "\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Parse the quality analysis response if it's in JSON format\n",
    "try:\n",
    "    quality_data = json.loads(quality_response.content)\n",
    "except json.JSONDecodeError:\n",
    "    quality_data = quality_response.content\n",
    "\n",
    "# Create a flattened dictionary for CSV\n",
    "flattened_results = {\n",
    "    'table_name': [table_name],\n",
    "    'timestamp': [timestamp]\n",
    "}\n",
    "\n",
    "# Add quality analysis data\n",
    "if isinstance(quality_data, dict):\n",
    "    for key, value in quality_data.items():\n",
    "        flattened_results[f'quality_{key}'] = [value]\n",
    "else:\n",
    "    flattened_results['data_quality_analysis'] = [quality_data]\n",
    "\n",
    "# Add semantic analysis\n",
    "flattened_results['semantic_analysis'] = [semantic_response.content]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(flattened_results)\n",
    "\n",
    "# Save to CSV\n",
    "csv_filename = f'analysis_results_{timestamp}.csv'\n",
    "df.to_csv(csv_filename, index=False, encoding='utf-8')\n",
    "print(f\"\\nResults saved to {csv_filename}\")\n",
    "\n",
    "# Display preview\n",
    "print(\"\\nPreview of CSV content:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Database connection closed\n"
     ]
    }
   ],
   "source": [
    "engine.dispose()\n",
    "print(\"\\nDatabase connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

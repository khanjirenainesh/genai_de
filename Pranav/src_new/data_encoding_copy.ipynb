{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake connection established\n",
      "Loaded 55501 rows from PATIENT_ADMISSIONS\n",
      "Training Isolation Forest with Grid Search...\n",
      "Training Local Outlier Factor...\n",
      "Training Robust Covariance...\n",
      "\n",
      "Found 11 anomalous records out of 55501 total records\n",
      "\n",
      "Top 5 most anomalous records:\n",
      "                    NAME  AGE  GENDER BLOOD_TYPE MEDICAL_CONDITION  \\\n",
      "3306      ALBerT wALteRs   80  Female         A+         Arthritis   \n",
      "49585     mATtHeW cARTeR   19    Male         O-         Arthritis   \n",
      "54671         jaDe BaKER   88  Female         O-           Obesity   \n",
      "19729      BRAdlEY bLAiR   19    Male         O-         Arthritis   \n",
      "28370  pHYLlIs florEs Md   77    Male         O-         Arthritis   \n",
      "\n",
      "      DATE_OF_ADMISSION          DOCTOR                  HOSPITAL  \\\n",
      "3306         2019-05-11  Shelby Walters    Cox Stone, and Merritt   \n",
      "49585        2023-06-20   Willie Carter            Fischer-Garner   \n",
      "54671        2021-05-31      Todd Evans  and Gray Smith, Jennings   \n",
      "19729        2020-01-18     Anita Craig           Adams-Velasquez   \n",
      "28370        2020-06-15   Brenda Morris    and Smith Dyer Vargas,   \n",
      "\n",
      "      INSURANCE_PROVIDER  BILLING_AMOUNT  ROOM_NUMBER ADMISSION_TYPE  \\\n",
      "3306            Medicare         4699.31          108       Elective   \n",
      "49585              Aetna        27644.21          110       Elective   \n",
      "54671   UnitedHealthcare         1990.27          488         Urgent   \n",
      "19729              Cigna         6481.97          490      Emergency   \n",
      "28370              Aetna         2616.85          495       Elective   \n",
      "\n",
      "      DISCHARGE_DATE  MEDICATION TEST_RESULTS  ensemble_anomaly_score  \\\n",
      "3306      2019-06-09  Penicillin     Abnormal                0.088623   \n",
      "49585     2023-07-18  Penicillin     Abnormal                0.091652   \n",
      "54671     2021-06-03     Lipitor       Normal                0.114027   \n",
      "19729     2020-02-17  Penicillin     Abnormal                0.120442   \n",
      "28370     2020-07-15     Lipitor     Abnormal                0.123818   \n",
      "\n",
      "       is_anomaly  \n",
      "3306         True  \n",
      "49585        True  \n",
      "54671        True  \n",
      "19729        True  \n",
      "28370        True  \n",
      "\n",
      "Saved anomalies to PATIENT_ADMISSIONS_anomalies_enhanced.csv\n",
      "\n",
      "Best parameters for Isolation Forest:\n",
      "{'contamination': 'auto', 'max_features': 0.5, 'max_samples': 0.3, 'n_estimators': 100}\n",
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.metrics import make_scorer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "load_dotenv(override=True)\n",
    "\n",
    "class AnomalyDetector:\n",
    "    def __init__(self, contamination=0.001):\n",
    "        self.contamination = contamination\n",
    "        self.models = {\n",
    "            'isolation_forest': None,\n",
    "            'local_outlier_factor': None,\n",
    "            'robust_covariance': None\n",
    "        }\n",
    "        self.best_params = {}\n",
    "        \n",
    "    def prepare_data(self, df):\n",
    "        \"\"\"Prepare data for anomaly detection\"\"\"\n",
    "        df_encoded = df.copy()\n",
    "        \n",
    "        # Encode categorical columns\n",
    "        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        if categorical_cols:\n",
    "            encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "            df_encoded[categorical_cols] = encoder.fit_transform(df[categorical_cols])\n",
    "        \n",
    "        # Scale numerical features\n",
    "        scaler = StandardScaler()\n",
    "        df_encoded = pd.DataFrame(scaler.fit_transform(df_encoded), columns=df_encoded.columns)\n",
    "        # display(df_encoded.head())\n",
    "        return df_encoded.fillna(0)\n",
    "\n",
    "    def grid_search_isolation_forest(self, X):\n",
    "        \"\"\"Perform grid search for IsolationForest\"\"\"\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_samples': [0.3, 0.5, 0.9],\n",
    "            'contamination': ['auto', 0.0002, 0.0005],\n",
    "            'max_features': [0.5, 0.7, 1.0]\n",
    "        }\n",
    "        \n",
    "        base_model = IsolationForest(random_state=42)\n",
    "        \n",
    "        # Custom scorer for anomaly detection\n",
    "        scorer = make_scorer(lambda y_true, y_pred: -np.mean(np.square(y_pred)), greater_is_better=False)\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=base_model,\n",
    "            param_grid=param_grid,\n",
    "            cv=3,\n",
    "            scoring=scorer,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X)\n",
    "        self.best_params['isolation_forest'] = grid_search.best_params_\n",
    "        return grid_search.best_estimator_\n",
    "\n",
    "    def detect_anomalies(self, df):\n",
    "        \"\"\"Detect anomalies using multiple methods\"\"\"\n",
    "        X = self.prepare_data(df)\n",
    "        \n",
    "        # Initialize results dictionary\n",
    "        results = {\n",
    "            'scores': {},\n",
    "            'labels': {},\n",
    "            'ensemble_score': None,\n",
    "            'ensemble_label': None\n",
    "        }\n",
    "        \n",
    "        # 1. Isolation Forest with Grid Search\n",
    "        print(\"Training Isolation Forest with Grid Search...\")\n",
    "        self.models['isolation_forest'] = self.grid_search_isolation_forest(X)\n",
    "        results['scores']['isolation_forest'] = self.models['isolation_forest'].decision_function(X)\n",
    "        results['labels']['isolation_forest'] = self.models['isolation_forest'].predict(X)\n",
    "        \n",
    "        # 2. Local Outlier Factor\n",
    "        print(\"Training Local Outlier Factor...\")\n",
    "        self.models['local_outlier_factor'] = LocalOutlierFactor(\n",
    "            contamination=self.contamination,\n",
    "            n_neighbors=20,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        results['labels']['lof'] = self.models['local_outlier_factor'].fit_predict(X)\n",
    "        results['scores']['lof'] = self.models['local_outlier_factor'].negative_outlier_factor_\n",
    "        \n",
    "        # 3. Robust Covariance (Elliptic Envelope)\n",
    "        print(\"Training Robust Covariance...\")\n",
    "        self.models['robust_covariance'] = EllipticEnvelope(\n",
    "            contamination=self.contamination,\n",
    "            random_state=42\n",
    "        )\n",
    "        results['labels']['robust_covariance'] = self.models['robust_covariance'].fit_predict(X)\n",
    "        results['scores']['robust_covariance'] = self.models['robust_covariance'].decision_function(X)\n",
    "        \n",
    "        # Ensemble scoring\n",
    "        results['ensemble_score'] = np.mean([\n",
    "            MinMaxScaler().fit_transform(results['scores'][model].reshape(-1, 1)).flatten()\n",
    "            for model in results['scores']\n",
    "        ], axis=0)\n",
    "        \n",
    "        # Ensemble labels (majority voting)\n",
    "        results['ensemble_label'] = np.mean([\n",
    "            results['labels'][model] == -1 for model in results['labels']\n",
    "        ], axis=0) >= 0.5\n",
    "        \n",
    "        return results\n",
    "\n",
    "def main():\n",
    "    # Snowflake connection setup\n",
    "    SNOWFLAKE_USER = os.environ.get(\"SNOWFLAKE_USER\")\n",
    "    SNOWFLAKE_PASSWORD = os.environ.get(\"SNOWFLAKE_PASSWORD\")\n",
    "    SNOWFLAKE_ACCOUNT = os.environ.get(\"SNOWFLAKE_ACCOUNT\")\n",
    "    SNOWFLAKE_WAREHOUSE = os.environ.get(\"SNOWFLAKE_WAREHOUSE\")\n",
    "    SNOWFLAKE_DATABASE = os.environ.get(\"SNOWFLAKE_DATABASE\")\n",
    "    SNOWFLAKE_SCHEMA = os.environ.get(\"SNOWFLAKE_SCHEMA\")\n",
    "\n",
    "    connection_string = (\n",
    "        f\"snowflake://{SNOWFLAKE_USER}:{SNOWFLAKE_PASSWORD}@\"\n",
    "        f\"{SNOWFLAKE_ACCOUNT}/{SNOWFLAKE_DATABASE}/{SNOWFLAKE_SCHEMA}\"\n",
    "        f\"?warehouse={SNOWFLAKE_WAREHOUSE}\"\n",
    "    )\n",
    "    \n",
    "    engine = create_engine(connection_string)\n",
    "    print(\"Snowflake connection established\")\n",
    "\n",
    "    # Get table to analyze\n",
    "    table_to_analyze = \"PATIENT_ADMISSIONS\"\n",
    "    \n",
    "    # Load data\n",
    "    query = f\"SELECT * FROM {SNOWFLAKE_DATABASE}.{SNOWFLAKE_SCHEMA}.{table_to_analyze}\"\n",
    "    with engine.connect() as conn:\n",
    "        df = pd.read_sql(query, conn.connection)\n",
    "    \n",
    "    print(f\"Loaded {len(df)} rows from {table_to_analyze}\")\n",
    "    \n",
    "    # Initialize and run anomaly detection\n",
    "    detector = AnomalyDetector(contamination=0.0001)\n",
    "    results = detector.detect_anomalies(df)\n",
    "    \n",
    "    # Add results to original dataframe\n",
    "    df['ensemble_anomaly_score'] = results['ensemble_score']\n",
    "    df['is_anomaly'] = results['ensemble_label']\n",
    "    \n",
    "    # Get anomalies and sort by ensemble score\n",
    "    anomalies = df[df['is_anomaly']].sort_values('ensemble_anomaly_score')\n",
    "    \n",
    "    print(f\"\\nFound {len(anomalies)} anomalous records out of {len(df)} total records\")\n",
    "    \n",
    "    if len(anomalies) > 0:\n",
    "        print(\"\\nTop 5 most anomalous records:\")\n",
    "        print(anomalies.head())\n",
    "        \n",
    "        # Save anomalies to CSV\n",
    "        output_file = f\"{table_to_analyze}_anomalies_enhanced.csv\"\n",
    "        anomalies.to_csv(output_file, index=False)\n",
    "        print(f\"\\nSaved anomalies to {output_file}\")\n",
    "        \n",
    "        # Print best parameters from grid search\n",
    "        print(\"\\nBest parameters for Isolation Forest:\")\n",
    "        print(detector.best_params['isolation_forest'])\n",
    "    else:\n",
    "        print(\"No anomalies detected in this table\")\n",
    "    \n",
    "    engine.dispose()\n",
    "    print(\"Connection closed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

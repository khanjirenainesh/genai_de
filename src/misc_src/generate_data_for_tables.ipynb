{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 33 column 51 (char 1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 149\u001b[0m\n\u001b[0;32m    146\u001b[0m     syn_data[\u001b[38;5;28mstr\u001b[39m(table_name)] \u001b[38;5;241m=\u001b[39m synthetic_data\n\u001b[0;32m    148\u001b[0m     parsed_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(json\u001b[38;5;241m.\u001b[39mdumps(syn_data))\n\u001b[1;32m--> 149\u001b[0m     final_data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m     syn_data[table_name] \u001b[38;5;241m=\u001b[39m final_data\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 33 column 51 (char 1024)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from  datetime import datetime\n",
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "import snowflake.connector\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any\n",
    "from azure.storage.filedatalake import DataLakeServiceClient\n",
    "from io import StringIO\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "env_vars = {\n",
    "        \"SNOWFLAKE_USER\": os.environ.get(\"SNOWFLAKE_USER\"),\n",
    "        \"SNOWFLAKE_PASSWORD\": os.environ.get(\"SNOWFLAKE_PASSWORD\"),\n",
    "        \"SNOWFLAKE_ACCOUNT\": os.environ.get(\"SNOWFLAKE_ACCOUNT\"),\n",
    "        \"SNOWFLAKE_WAREHOUSE\": os.environ.get(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "        \"SNOWFLAKE_DATABASE\": os.environ.get(\"SNOWFLAKE_DATABASE\"),\n",
    "        \"SNOWFLAKE_SCHEMA\": os.environ.get(\"SNOWFLAKE_SCHEMA\"),\n",
    "        \"AZURE_OPENAI_ENDPOINT\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        \"AZURE_OPENAI_4o_DEPLOYMENT_NAME\": os.environ.get(\"AZURE_OPENAI_4o_DEPLOYMENT_NAME\"),\n",
    "        \"AZURE_OPENAI_API_VERSION\": os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "        \"AZURE_OPENAI_API_KEY\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    }\n",
    "\n",
    "conn = snowflake.connector.connect(\n",
    "        user=env_vars.get(\"SNOWFLAKE_USER\"),\n",
    "        password=env_vars.get(\"SNOWFLAKE_PASSWORD\"),\n",
    "        account=env_vars.get(\"SNOWFLAKE_ACCOUNT\"),\n",
    "        warehouse=env_vars.get(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "        database=env_vars.get(\"SNOWFLAKE_DATABASE\"),\n",
    "        schema=env_vars.get(\"SNOWFLAKE_SCHEMA\"),\n",
    "    )\n",
    "\n",
    "model = AzureChatOpenAI(\n",
    "        azure_endpoint=env_vars.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        azure_deployment=env_vars.get(\"AZURE_OPENAI_4o_DEPLOYMENT_NAME\"),\n",
    "        openai_api_version=env_vars.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "        openai_api_key=env_vars.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "cursor = conn.cursor()\n",
    "azure_storage_connection_string = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "\n",
    "adls_client = DataLakeServiceClient.from_connection_string(azure_storage_connection_string)\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "        SELECT table_name \n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema = 'TEST' AND table_type = 'BASE TABLE'\n",
    "    \"\"\")\n",
    "\n",
    "tables =  cursor.fetchall()\n",
    "\n",
    "\n",
    "table_names = [table[0] for table in tables]\n",
    "# Initialize an empty dictionary to store data from all tables\n",
    "all_data = {}\n",
    "# Fetch data from all tables\n",
    "for table_name in table_names:\n",
    "    cursor.execute(f\"SELECT * FROM {table_name}\")  # Limit the rows for simplicity\n",
    "    data2 = cursor.fetchall()\n",
    "    df = pd.DataFrame(data2, columns=[col[0] for col in cursor.description])\n",
    "    all_data[table_name] = df\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "    SELECT \n",
    "        TABLE_NAME, \n",
    "        COLUMN_NAME, \n",
    "        DATA_TYPE, \n",
    "        IS_NULLABLE, \n",
    "        COLUMN_DEFAULT \n",
    "    FROM \n",
    "        INFORMATION_SCHEMA.COLUMNS\n",
    "    WHERE \n",
    "        TABLE_SCHEMA = 'TEST'\n",
    "    ORDER BY table_name\n",
    "\"\"\")\n",
    "\n",
    "metadata = cursor.fetchall()\n",
    "tables = {}\n",
    "\n",
    "for table_name, column_name, data_type, is_nullable, _ in metadata:\n",
    "    if table_name not in tables:\n",
    "        tables[table_name] = []\n",
    "    \n",
    "    tables[table_name].append({\n",
    "        \"column_name\": column_name,\n",
    "        \"data_type\": data_type,\n",
    "        \"is_nullable\": is_nullable\n",
    "    })\n",
    "\n",
    "json_data = json.dumps(tables, indent=4)\n",
    "splitter = RecursiveJsonSplitter(max_chunk_size=300)\n",
    "texts = splitter.split_text(json_data=json.loads(json_data))\n",
    "\n",
    "\n",
    "syn_data = {}\n",
    "prompt_template = \"\"\"\n",
    "    Generate 1 row of good and bad-quality data for each table based on the given metadata. \n",
    "    All data should strictly comply with constraints and data types of respective tables, \n",
    "    while bad data should simulate realistic yet invalid scenarios violating constraints like:\n",
    "    1. Negative or illogical values (e.g., negative age or weight).\n",
    "    2. Invalid or out-of-range dates (e.g., February 30, year > 9999).\n",
    "    3. Nullability violations (e.g., null in non-nullable fields).\n",
    "    4. Duplicate primary keys.\n",
    "    5. Logical inconsistencies (e.g., start date after end date).\n",
    "    6. missing values.\n",
    "    \n",
    "    \n",
    "    Output format: \n",
    "    please DO NOT give invalid timestamp data.\n",
    "    strictly Provide a JSON array format containing serializable data for each table.\n",
    "    Provide the output in pure json JSON array format which I can parse as a json data to various platforms.\n",
    "    Generate json serializable data.\n",
    "    Dont provide any comments in between and any description.\n",
    "    dont repeat table name inside the json data.\n",
    "    Only json format data is allowed without any // comment in it.\n",
    "    This is required format in which we require generated data.\n",
    "\n",
    "    here is the input table Metadata: \n",
    "    {metadata}\n",
    "\n",
    "    \"\"\"\n",
    "for i in range(10): #(len(tex)):\n",
    "\n",
    "    # Create the prompt\n",
    "    prompt = PromptTemplate(input_variables=[\"metadata\"], template=prompt_template)\n",
    "    formatted_prompt = prompt.format(metadata=texts[i])\n",
    "    \n",
    "    df1 = texts[i]\n",
    "    metadata_dict1 = json.loads(df1)\n",
    "    table_name = list(metadata_dict1.keys())[0]\n",
    "    # print(formatted_prompt)\n",
    "    response = model.invoke(formatted_prompt)\n",
    "\n",
    "    synthetic_data = response.content.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "    # Display the result\n",
    "    syn_data[str(table_name)] = synthetic_data\n",
    "\n",
    "    parsed_data = json.loads(json.dumps(syn_data))\n",
    "    final_data = json.loads(parsed_data[table_name])\n",
    "\n",
    "    syn_data[table_name] = final_data\n",
    "   \n",
    "try:\n",
    "    data1 = json.dumps(syn_data)\n",
    "except json.JSONDecodeError:\n",
    "    print(\"Error: Failed to parse generated JSON data.\")\n",
    "    data1 = []\n",
    "    \n",
    "\n",
    "\n",
    "# Data in JSON format\n",
    "data = json.loads(data1)\n",
    "\n",
    "output_dir = \"test_output1\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process each table\n",
    "for table_name, rows in data.items():\n",
    "    if rows:  # Check if the table has data\n",
    "        # Define output CSV file path\n",
    "        output_csv_file = os.path.join(output_dir, f\"{table_name}.csv\")\n",
    "        \n",
    "        # Get column names from the first row\n",
    "        column_names = rows[0].keys()\n",
    "\n",
    "        # Write data to CSV file\n",
    "        with open(output_csv_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=column_names)\n",
    "            \n",
    "            # Write header and rows\n",
    "            writer.writeheader()\n",
    "            writer.writerows(rows)\n",
    "\n",
    "        print(f\"Table '{table_name}' saved to {output_csv_file}\")\n",
    "    else:\n",
    "        print(f\"Table '{table_name}' is empty. No file created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet langchain_experimental langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0df8f905-2897-4ad5-a5da-4386f45527ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import snowflake.connector\n",
    "from typing import List, Dict\n",
    "import logging\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d6da4f3-bc25-4101-81e3-878caab760ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ab5ed798-7825-46f8-88f6-a6850ae66a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ignore this now\n",
    "# class SnowflakeFailureTester:\n",
    "#     def __init__(self):\n",
    "#         \"\"\"\n",
    "#         Initialize connections to Snowflake and Azure OpenAI using environment variables\n",
    "#         \"\"\"\n",
    "#         # Load Snowflake credentials from environment variables\n",
    "#         self.snow_conn = snowflake.connector.connect(\n",
    "#             user=os.getenv('SNOWFLAKE_USER'),\n",
    "#             password=os.getenv('SNOWFLAKE_PASSWORD'),\n",
    "#             account=os.getenv('SNOWFLAKE_ACCOUNT'),\n",
    "#             warehouse=os.getenv('SNOWFLAKE_WAREHOUSE'),\n",
    "#             database=os.getenv('SNOWFLAKE_DATABASE'),\n",
    "#             schema=os.getenv('SNOWFLAKE_SCHEMA')\n",
    "#         )\n",
    "        \n",
    "#         # Load Azure OpenAI credentials from environment variables\n",
    "#         self.openai_client = AzureOpenAI(\n",
    "#             api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "#             api_version=os.getenv('AZURE_OPENAI_API_VERSION'),\n",
    "#             azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "#         )\n",
    "        \n",
    "#         self.failure_scenarios = {\n",
    "#             'data_type_mismatch': self._generate_type_mismatch_data,\n",
    "#             'out_of_range_values': self._generate_out_of_range_data,\n",
    "#             'null_violations': self._generate_null_violations,\n",
    "#             'unique_constraint_violations': self._generate_unique_violations,\n",
    "#             'foreign_key_violations': self._generate_fk_violations\n",
    "#         }\n",
    "        \n",
    "#     def get_table_metadata(self, table_name: str) -> Dict:\n",
    "#         \"\"\"\n",
    "#         Fetch table metadata from Snowflake\n",
    "#         \"\"\"\n",
    "#         cursor = self.snow_conn.cursor()\n",
    "#         try:\n",
    "#             # Get column information\n",
    "#             cursor.execute(f\"\"\"\n",
    "#                 SELECT COLUMN_NAME, DATA_TYPE, IS_NULLABLE, CHARACTER_MAXIMUM_LENGTH,\n",
    "#                        NUMERIC_PRECISION, NUMERIC_SCALE\n",
    "#                 FROM INFORMATION_SCHEMA.COLUMNS\n",
    "#                 WHERE TABLE_NAME = '{table_name}'\n",
    "#                 ORDER BY ORDINAL_POSITION\n",
    "#             \"\"\")\n",
    "#             columns = cursor.fetchall()\n",
    "            \n",
    "#             # Get constraints information\n",
    "#             cursor.execute(f\"\"\"\n",
    "#                 SELECT CONSTRAINT_TYPE, CONSTRAINT_NAME, COLUMN_NAME\n",
    "#                 FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS tc\n",
    "#                 JOIN INFORMATION_SCHEMA.CONSTRAINT_COLUMN_USAGE cc \n",
    "#                     ON tc.CONSTRAINT_NAME = cc.CONSTRAINT_NAME\n",
    "#                 WHERE tc.TABLE_NAME = '{table_name}'\n",
    "#             \"\"\")\n",
    "#             constraints = cursor.fetchall()\n",
    "            \n",
    "#             return {\n",
    "#                 'columns': columns,\n",
    "#                 'constraints': constraints\n",
    "#             }\n",
    "#         finally:\n",
    "#             cursor.close()\n",
    "\n",
    "#     def _generate_type_mismatch_data(self, metadata: Dict) -> pd.DataFrame:\n",
    "#         \"\"\"\n",
    "#         Generate data with intentional type mismatches\n",
    "#         \"\"\"\n",
    "#         prompt = f\"\"\"\n",
    "#         Generate 5 rows of data that would cause type mismatch errors for the following columns:\n",
    "#         {json.dumps(metadata['columns'])}\n",
    "#         Format the response as a JSON array of objects with intentional type mismatches.\n",
    "#         \"\"\"\n",
    "        \n",
    "#         response = self.openai_client.chat.completions.create(\n",
    "#             model=\"gpt-4\",\n",
    "#             messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "#         )\n",
    "        \n",
    "#         data = json.loads(response.choices[0].message.content)\n",
    "#         return pd.DataFrame(data)\n",
    "\n",
    "#     def _generate_out_of_range_data(self, metadata: Dict) -> pd.DataFrame:\n",
    "#         \"\"\"\n",
    "#         Generate data with out-of-range values\n",
    "#         \"\"\"\n",
    "#         prompt = f\"\"\"\n",
    "#         Generate 5 rows of data with out-of-range values for numeric and date columns:\n",
    "#         {json.dumps(metadata['columns'])}\n",
    "#         Include values that exceed maximum/minimum bounds for numeric types,\n",
    "#         and invalid dates for date types. Format as JSON array.\n",
    "#         \"\"\"\n",
    "        \n",
    "#         response = self.openai_client.chat.completions.create(\n",
    "#             model=\"gpt-4\",\n",
    "#             messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "#         )\n",
    "        \n",
    "#         data = json.loads(response.choices[0].message.content)\n",
    "#         return pd.DataFrame(data)\n",
    "\n",
    "#     def _generate_null_violations(self, metadata: Dict) -> pd.DataFrame:\n",
    "#         \"\"\"\n",
    "#         Generate data with NULL values for non-nullable columns\n",
    "#         \"\"\"\n",
    "#         prompt = f\"\"\"\n",
    "#         Generate 5 rows of data with NULL values for non-nullable columns:\n",
    "#         {json.dumps(metadata['columns'])}\n",
    "#         Format as JSON array with strategic NULL placements.\n",
    "#         \"\"\"\n",
    "        \n",
    "#         response = self.openai_client.chat.completions.create(\n",
    "#             model=\"gpt-4\",\n",
    "#             messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "#         )\n",
    "        \n",
    "#         data = json.loads(response.choices[0].message.content)\n",
    "#         return pd.DataFrame(data)\n",
    "\n",
    "#     def _generate_unique_violations(self, metadata: Dict) -> pd.DataFrame:\n",
    "#         \"\"\"\n",
    "#         Generate data that violates unique constraints\n",
    "#         \"\"\"\n",
    "#         cursor = self.snow_conn.cursor()\n",
    "#         try:\n",
    "#             # First get some existing values\n",
    "#             unique_columns = [c[2] for c in metadata['constraints'] \n",
    "#                             if c[0] == 'UNIQUE']\n",
    "#             if unique_columns:\n",
    "#                 column_list = ', '.join(unique_columns)\n",
    "#                 cursor.execute(f\"SELECT {column_list} FROM {table_name} LIMIT 5\")\n",
    "#                 existing_values = cursor.fetchall()\n",
    "                \n",
    "#                 prompt = f\"\"\"\n",
    "#                 Generate 5 rows of data that violate unique constraints by reusing these values:\n",
    "#                 Existing values: {existing_values}\n",
    "#                 Unique columns: {unique_columns}\n",
    "#                 Format as JSON array.\n",
    "#                 \"\"\"\n",
    "                \n",
    "#                 response = self.openai_client.chat.completions.create(\n",
    "#                     model=\"gpt-4\",\n",
    "#                     messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "#                 )\n",
    "                \n",
    "#                 data = json.loads(response.choices[0].message.content)\n",
    "#                 return pd.DataFrame(data)\n",
    "#         finally:\n",
    "#             cursor.close()\n",
    "\n",
    "#     def _generate_fk_violations(self, metadata: Dict) -> pd.DataFrame:\n",
    "#         \"\"\"\n",
    "#         Generate data that violates foreign key constraints\n",
    "#         \"\"\"\n",
    "#         # Similar to unique violations but for foreign keys\n",
    "#         # Would need to analyze referenced tables as well\n",
    "#         pass\n",
    "\n",
    "#     def test_table(self, table_name: str, scenario: str = 'all') -> Dict:\n",
    "#         \"\"\"\n",
    "#         Run failure tests on a specific table\n",
    "#         \"\"\"\n",
    "#         results = {\n",
    "#             'table_name': table_name,\n",
    "#             'timestamp': datetime.now().isoformat(),\n",
    "#             'scenarios_tested': [],\n",
    "#             'failures': []\n",
    "#         }\n",
    "        \n",
    "#         metadata = self.get_table_metadata(table_name)\n",
    "        \n",
    "#         scenarios = [scenario] if scenario != 'all' else self.failure_scenarios.keys()\n",
    "        \n",
    "#         for scenario_name in scenarios:\n",
    "#             try:\n",
    "#                 if scenario_name in self.failure_scenarios:\n",
    "#                     logger.info(f\"Testing scenario: {scenario_name}\")\n",
    "                    \n",
    "#                     # Generate test data\n",
    "#                     test_data = self.failure_scenarios[scenario_name](metadata)\n",
    "                    \n",
    "#                     # Try to insert the data\n",
    "#                     cursor = self.snow_conn.cursor()\n",
    "#                     try:\n",
    "#                         for _, row in test_data.iterrows():\n",
    "#                             insert_sql = f\"\"\"\n",
    "#                                 INSERT INTO {table_name}\n",
    "#                                 ({', '.join(row.index)})\n",
    "#                                 VALUES ({', '.join(['%s'] * len(row))})\n",
    "#                             \"\"\"\n",
    "#                             try:\n",
    "#                                 cursor.execute(insert_sql, tuple(row))\n",
    "#                                 # If we get here, the failure test failed (data was inserted successfully)\n",
    "#                                 results['failures'].append({\n",
    "#                                     'scenario': scenario_name,\n",
    "#                                     'unexpected_success': True,\n",
    "#                                     'data': row.to_dict()\n",
    "#                                 })\n",
    "#                             except Exception as e:\n",
    "#                                 # This is actually what we want - log the error\n",
    "#                                 results['failures'].append({\n",
    "#                                     'scenario': scenario_name,\n",
    "#                                     'error_message': str(e),\n",
    "#                                     'data': row.to_dict()\n",
    "#                                 })\n",
    "#                     finally:\n",
    "#                         cursor.close()\n",
    "                        \n",
    "#                     results['scenarios_tested'].append(scenario_name)\n",
    "                    \n",
    "#             except Exception as e:\n",
    "#                 logger.error(f\"Error in scenario {scenario_name}: {str(e)}\")\n",
    "#                 results['failures'].append({\n",
    "#                     'scenario': scenario_name,\n",
    "#                     'error': str(e),\n",
    "#                     'stage': 'scenario_execution'\n",
    "#                 })\n",
    "        \n",
    "#         return results\n",
    "\n",
    "#     def test_schema(self, exclude_tables: List[str] = None) -> Dict:\n",
    "#         \"\"\"\n",
    "#         Test all tables in the schema\n",
    "#         \"\"\"\n",
    "#         cursor = self.snow_conn.cursor()\n",
    "#         try:\n",
    "#             cursor.execute(\"\"\"\n",
    "#                 SELECT TABLE_NAME \n",
    "#                 FROM INFORMATION_SCHEMA.TABLES \n",
    "#                 WHERE TABLE_SCHEMA = CURRENT_SCHEMA()\n",
    "#             \"\"\")\n",
    "#             tables = [row[0] for row in cursor.fetchall()]\n",
    "            \n",
    "#             if exclude_tables:\n",
    "#                 tables = [t for t in tables if t not in exclude_tables]\n",
    "            \n",
    "#             results = {}\n",
    "#             for table in tables:\n",
    "#                 results[table] = self.test_table(table)\n",
    "            \n",
    "#             return results\n",
    "#         finally:\n",
    "#             cursor.close()\n",
    "\n",
    "#     def save_results(self, results: Dict, output_path: str):\n",
    "#         \"\"\"\n",
    "#         Save test results to a file\n",
    "#         \"\"\"\n",
    "#         with open(output_path, 'w') as f:\n",
    "#             json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a52b38-4236-46cc-8c6f-f01a0801867e",
   "metadata": {},
   "source": [
    "## db and api connection testing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e37dde56-80c5-45b7-8486-c920eae8ffd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.connection:Snowflake Connector for Python Version: 3.12.4, Python Version: 3.12.8, Platform: Windows-11-10.0.22631-SP0\n",
      "INFO:snowflake.connector.connection:Connecting to GLOBAL Snowflake domain\n",
      "INFO:snowflake.connector.connection:This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake connection established\n",
      "Error establishing connections: module 'openai' has no attribute 'AzureOpenAI'\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import snowflake.connector\n",
    "from typing import List, Dict\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import os\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Initialize Snowflake connection\n",
    "def init_snowflake():\n",
    "    return snowflake.connector.connect(\n",
    "        user = 'ashika',\n",
    "        password = 'Cervello123#',\n",
    "        account = 'bpwmwqd-bk67062',\n",
    "        warehouse = 'compute_wh',\n",
    "        database = 'RAW',\n",
    "        schema = 'test',\n",
    "    )\n",
    "\n",
    "# Initialize Azure OpenAI client\n",
    "def init_openai():\n",
    "    return AzureChatOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_4o_DEPLOYMENT_NAME\"],\n",
    "    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    openai_api_key = os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    ")\n",
    "\n",
    "\n",
    "try:\n",
    "    snow_conn = init_snowflake()\n",
    "    print(\"Snowflake connection established\")\n",
    "    \n",
    "    openai_client = init_openai()\n",
    "    print(\"Azure OpenAI connection established\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error establishing connections: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf32f9a9",
   "metadata": {},
   "source": [
    "## create the metadata retrieval function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe5605b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved metadata for table USERS\n",
      "Columns: [('USER_ID', 'NUMBER', 'NO', None, 38, 0), ('USERNAME', 'TEXT', 'NO', 16777216, None, None), ('EMAIL', 'TEXT', 'NO', 16777216, None, None), ('PASSWORD', 'TEXT', 'NO', 16777216, None, None), ('ROLE', 'TEXT', 'NO', 16777216, None, None)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_table_metadata(conn, table_name: str) -> Dict:\n",
    "    \"\"\"Fetch table metadata from Snowflake\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        # Get column information\n",
    "        cursor.execute(f\"\"\"\n",
    "            SELECT COLUMN_NAME, DATA_TYPE, IS_NULLABLE, CHARACTER_MAXIMUM_LENGTH,\n",
    "                   NUMERIC_PRECISION, NUMERIC_SCALE\n",
    "            FROM INFORMATION_SCHEMA.COLUMNS\n",
    "            WHERE TABLE_NAME = '{table_name}'\n",
    "            ORDER BY ORDINAL_POSITION\n",
    "        \"\"\")\n",
    "        columns = cursor.fetchall()\n",
    "    \n",
    "\n",
    "        # cursor.execute(f\"\"\"\n",
    "        #     SELECT CONSTRAINT_TYPE, CONSTRAINT_NAME\n",
    "        #     FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS\n",
    "        #     WHERE TABLE_NAME = '{table_name}'\n",
    "        # \"\"\")\n",
    "        # constraints = cursor.fetchall()\n",
    "        \n",
    "        return {\n",
    "            'columns': columns\n",
    "            # 'constraints': constraints\n",
    "        }\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "        \n",
    "\n",
    "try:\n",
    "    test_table = \"USERS\"  # need to make this iterative over all tables in given schema\n",
    "    metadata = get_table_metadata(snow_conn, test_table)\n",
    "    print(f\"Retrieved metadata for table {test_table}\")\n",
    "    print(\"Columns:\", metadata['columns'])\n",
    "    # print(\"Constraints:\", metadata['constraints'])\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving metadata: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "018820b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:Number of results in first chunk: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved metadata for table USERS\n",
      "Columns: [('USERS', 'USER_ID', 'NUMBER', 'NO'), ('USERS', 'USERNAME', 'TEXT', 'NO'), ('USERS', 'EMAIL', 'TEXT', 'NO'), ('USERS', 'PASSWORD', 'TEXT', 'NO'), ('USERS', 'ROLE', 'TEXT', 'NO')]\n"
     ]
    }
   ],
   "source": [
    "def get_table_metadata(conn, table_name: str) -> Dict:\n",
    "    \"\"\"Fetch table metadata from Snowflake\"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        # Get column information\n",
    "        cursor.execute(f\"\"\"\n",
    "            SELECT table_name, column_name, data_type, is_nullable\n",
    "            FROM INFORMATION_SCHEMA.COLUMNS\n",
    "            WHERE TABLE_NAME = '{table_name}'\n",
    "            ORDER BY ORDINAL_POSITION\n",
    "        \"\"\")\n",
    "        columns = cursor.fetchall()\n",
    "    \n",
    "\n",
    "        # cursor.execute(f\"\"\"\n",
    "        #     SELECT CONSTRAINT_TYPE, CONSTRAINT_NAME\n",
    "        #     FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS\n",
    "        #     WHERE TABLE_NAME = '{table_name}'\n",
    "        # \"\"\")\n",
    "        # constraints = cursor.fetchall()\n",
    "        \n",
    "        return {\n",
    "            'columns': columns\n",
    "            # 'constraints': constraints\n",
    "        }\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "        \n",
    "\n",
    "try:\n",
    "    test_table = \"USERS\"  # need to make this iterative over all tables in given schema\n",
    "    metadata = get_table_metadata(snow_conn, test_table)\n",
    "    print(f\"Retrieved metadata for table {test_table}\")\n",
    "    print(\"Columns:\", metadata['columns'])\n",
    "    # print(\"Constraints:\", metadata['constraints'])\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving metadata: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26132d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"USERS\": [\n",
      "        {\n",
      "            \"column_name\": \"USER_ID\",\n",
      "            \"data_type\": \"NUMBER\",\n",
      "            \"is_nullable\": \"NO\"\n",
      "        },\n",
      "        {\n",
      "            \"column_name\": \"USERNAME\",\n",
      "            \"data_type\": \"TEXT\",\n",
      "            \"is_nullable\": \"NO\"\n",
      "        },\n",
      "        {\n",
      "            \"column_name\": \"EMAIL\",\n",
      "            \"data_type\": \"TEXT\",\n",
      "            \"is_nullable\": \"NO\"\n",
      "        },\n",
      "        {\n",
      "            \"column_name\": \"PASSWORD\",\n",
      "            \"data_type\": \"TEXT\",\n",
      "            \"is_nullable\": \"NO\"\n",
      "        },\n",
      "        {\n",
      "            \"column_name\": \"ROLE\",\n",
      "            \"data_type\": \"TEXT\",\n",
      "            \"is_nullable\": \"NO\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tables = {}\n",
    "\n",
    "# Loop through each column data tuple\n",
    "for table_name, column_name, data_type, is_nullable in metadata['columns']:\n",
    "    # Initialize a new table in the dictionary if it doesn't exist\n",
    "    if table_name not in tables:\n",
    "        tables[table_name] = []\n",
    "    \n",
    "    # Add a new entry for the column in the table\n",
    "    tables[table_name].append({\n",
    "        \"column_name\": column_name,\n",
    "        \"data_type\": data_type,\n",
    "        \"is_nullable\": is_nullable # Using None as placeholder value\n",
    "    })\n",
    "\n",
    "# Convert the tables dictionary to JSON format\n",
    "json_data = json.dumps(tables, indent=4)\n",
    "\n",
    "# Output the JSON data\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda6f161",
   "metadata": {},
   "source": [
    "## create the data generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating test data: 1 validation error for LLMPredictStartEvent\n",
      "template\n",
      "  Input should be a valid dictionary or instance of BasePromptTemplate [type=model_type, input_value='\\n    Generate 5 rows of... type mismatches.\\n    ', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/model_type\n"
     ]
    }
   ],
   "source": [
    "def generate_type_mismatch_data(client, metadata: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Generate data with intentional type mismatches\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Generate 5 rows of data that would cause type mismatch errors for the following columns:\n",
    "    {json.dumps(metadata['columns'])}\n",
    "    Format the response as a JSON array of objects with intentional type mismatches.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.predict(prompt)\n",
    "    data = json.loads(response)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def generate_null_violations(client, metadata: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Generate data with NULL values for non-nullable columns\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Generate 5 rows of data with NULL values for non-nullable columns:\n",
    "    {json.dumps(metadata['columns'])}\n",
    "    Format as JSON array with strategic NULL placements.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.predict(prompt)\n",
    "    data = json.loads(response)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Test data generation\n",
    "try:\n",
    "    test_data_type = generate_type_mismatch_data(openai_client, metadata)\n",
    "    print(\"Generated type mismatch data:\")\n",
    "    print(test_data_type)\n",
    "    \n",
    "    test_data_null = generate_null_violations(openai_client, metadata)\n",
    "    print(\"\\nGenerated null violation data:\")\n",
    "# Test data generation\n",
    "# try:\n",
    "#     # Use the llm instance that's already configured\n",
    "#     test_data_type = generate_type_mismatch_data(llm, metadata)\n",
    "#     print(\"Generated type mismatch data:\")\n",
    "#     print(test_data_type)\n",
    "    \n",
    "#     test_data_null = generate_null_violations(llm, metadata)\n",
    "#     print(\"\\nGenerated null violation data:\")\n",
    "#     print(test_data_null)\n",
    "except Exception as e:\n",
    "    print(f\"Error generating test data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m         formatted \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_nullable\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m formatted\n\u001b[1;32m----> 9\u001b[0m formatted_schema \u001b[38;5;241m=\u001b[39m format_schema(\u001b[43mtables\u001b[49m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Define the prompt\u001b[39;00m\n\u001b[0;32m     12\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124mBased on the following table schema, generate 5 rows of synthetic data:\u001b[39m\n\u001b[0;32m     14\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124mThe output should be in JSON format with an array of objects, where each object represents a row.\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tables' is not defined"
     ]
    }
   ],
   "source": [
    "def format_schema(tables):\n",
    "    formatted = \"Table: USERS\\n\"\n",
    "    formatted += \"Column Name | Data Type | Is Nullable\\n\"\n",
    "    formatted += \"-\" * 35 + \"\\n\"\n",
    "    for column in tables[\"USERS\"]:\n",
    "        formatted += f\"{column['column_name']} | {column['data_type']} | {column['is_nullable']}\\n\"\n",
    "    return formatted\n",
    "\n",
    "formatted_schema = format_schema(tables)\n",
    "\n",
    "# Define the prompt\n",
    "prompt = f\"\"\"\n",
    "Based on the following table schema, generate 5 rows of synthetic data:\n",
    "\n",
    "{formatted_schema}\n",
    "\n",
    "The output should be in JSON format with an array of objects, where each object represents a row.\n",
    "\"\"\"\n",
    "\n",
    "# Query the Azure OpenAI API\n",
    "def generate_synthetic_data(prompt):\n",
    "    response = openai.Completion.create(\n",
    "        engine=os.getenv(\"AZURE_OPENAI_MODEL_NAME\"),  # Azure model name\n",
    "        prompt=prompt,\n",
    "        max_tokens=300,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "# Generate synthetic data\n",
    "try:\n",
    "    synthetic_data = generate_synthetic_data(prompt)\n",
    "    print(\"Raw Output from Azure OpenAI:\")\n",
    "    print(synthetic_data)\n",
    "    \n",
    "    # Parse the response to ensure it's valid JSON\n",
    "    try:\n",
    "        synthetic_data_json = json.loads(synthetic_data)  # Converts string to JSON object\n",
    "        df = pd.DataFrame(synthetic_data_json)\n",
    "        print(\"\\nGenerated DataFrame:\")\n",
    "        print(df)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Failed to parse JSON. Check the raw response for issues.\")\n",
    "        print(\"Error Details:\", str(e))\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error generating synthetic data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating type mismatch data: 1 validation error for LLMPredictStartEvent\n",
      "template\n",
      "  Input should be a valid dictionary or instance of BasePromptTemplate [type=model_type, input_value='\\n    Generate 5 rows of... type mismatches.\\n    ', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/model_type\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_type_mismatch_data(openai_client,tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating test data: 1 validation error for LLMPredictStartEvent\n",
      "template\n",
      "  Input should be a valid dictionary or instance of BasePromptTemplate [type=model_type, input_value='\\n    Generate 5 rows of... type mismatches.\\n    ', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/model_type\n"
     ]
    }
   ],
   "source": [
    "def generate_type_mismatch_data(client, metadata: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Generate data with intentional type mismatches\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Generate 5 rows of data that would cause type mismatch errors for the following columns:\n",
    "    {json.dumps(tables)}\n",
    "    Format the response as a JSON array of objects with intentional type mismatches.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.predict(prompt)\n",
    "    # data = json.loads(response)\n",
    "    # return pd.DataFrame(data)\n",
    "    return response\n",
    "\n",
    "def generate_null_violations(client, metadata: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Generate data with NULL values for non-nullable columns\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Generate 5 rows of data with NULL values for non-nullable columns:\n",
    "    {json.dumps(tables)}\n",
    "    Format as JSON array with strategic NULL placements.\n",
    "    Give data that can used in json.loads()\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.predict(prompt)\n",
    "    #data = json.loads(response)\n",
    "    #return pd.DataFrame(data)\n",
    "    return response\n",
    "\n",
    "# Test data generation\n",
    "try:\n",
    "    test_data_type = generate_type_mismatch_data(openai_client, metadata)\n",
    "    print(\"Generated type mismatch data:\")\n",
    "    print(test_data_type)\n",
    "    \n",
    "    test_data_null = generate_null_violations(openai_client, metadata)\n",
    "    print(\"\\nGenerated null violation data:\")\n",
    "# Test data generation\n",
    "# try:\n",
    "#     # Use the llm instance that's already configured\n",
    "#     test_data_type = generate_type_mismatch_data(llm, metadata)\n",
    "#     print(\"Generated type mismatch data:\")\n",
    "#     print(test_data_type)\n",
    "    \n",
    "#     test_data_null = generate_null_violations(llm, metadata)\n",
    "#     print(\"\\nGenerated null violation data:\")\n",
    "#     print(test_data_null)\n",
    "except Exception as e:\n",
    "    print(f\"Error generating test data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e288f094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating test data: 1 validation error for LLMPredictStartEvent\n",
      "template\n",
      "  Input should be a valid dictionary or instance of BasePromptTemplate [type=model_type, input_value='\\n    Generate 5 rows of... type mismatches.\\n    ', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/model_type\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "\n",
    "def generate_type_mismatch_data(client, metadata: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Generate data with intentional type mismatches\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Generate 5 rows of data that would cause type mismatch errors for the following columns:\n",
    "    {json.dumps(metadata['columns'])}\n",
    "    Format the response as a JSON array of objects with intentional type mismatches.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Send the prompt to the Azure OpenAI client\n",
    "    response = client.predict(prompt)\n",
    "    \n",
    "    # Parse the response into JSON\n",
    "    data = json.loads(response)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def generate_null_violations(client, metadata: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Generate data with NULL values for non-nullable columns\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Generate 5 rows of data with NULL values for non-nullable columns:\n",
    "    {json.dumps(metadata['columns'])}\n",
    "    Format as JSON array with strategic NULL placements.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Send the prompt to the Azure OpenAI client\n",
    "    response = client.predict(prompt)\n",
    "    \n",
    "    # Parse the response into JSON\n",
    "    data = json.loads(response)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Test data generation\n",
    "try:\n",
    "    \n",
    "    test_data_type = generate_type_mismatch_data(openai_client, metadata)\n",
    "    print(\"Generated type mismatch data:\")\n",
    "    print(test_data_type)\n",
    "    \n",
    "    test_data_null = generate_null_violations(openai_client, metadata)\n",
    "    print(\"\\nGenerated null violation data:\")\n",
    "    print(test_data_null)\n",
    "except Exception as e:\n",
    "    print(f\"Error generating test data: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b0b9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544435b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b848686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154b5c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709809fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f254f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0f6daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2907e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809bec23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96a3187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306f3c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f6d347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dd6767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29180ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440efac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2efe95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e1db25d",
   "metadata": {},
   "source": [
    "## AI connection working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db079345-97db-4780-affe-b692db12662f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response with gpt-4o: What is the capital of France?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "# from llama_index.legacy.llms.azure_openai import AzureOpenAI\n",
    "\n",
    "# Initialize the AzureOpenAI instance with the loaded API key and endpoint\n",
    "## PS. model is not a required attribute for azure openai \n",
    "## if you specify azure_deployment, but it affects llm.model attribute in this instance\n",
    "llm = AzureOpenAI(\n",
    "    engine=os.getenv(\"AZURE_OPENAI_4o_MODEL_NAME\"), \n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_4o_DEPLOYMENT_NAME\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Define a simple prompt\n",
    "prompt = \"What is the capital of France?\"\n",
    "\n",
    "# Execute the chain\n",
    "## PS. if you use from llama_index.legacy.llms.azure_openai import AzureOpenAI\n",
    "## please change to response = llm.complete(prompt)\n",
    "r = llm.completion_to_prompt(prompt=prompt)\n",
    "# response = llm.complete(prompt)\n",
    "\n",
    "# Display the response from current model\n",
    "print(f\"Response with {llm.azure_deployment}: {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018286de-31ed-4c7c-97ed-31d23cb06317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91d8e54-6bcc-4309-84e2-5eef14623dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4ebc41-1b33-4a6d-85da-55eec07973e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b502d5b-0dec-4a5d-8fac-32bbbf1cf633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1f267f-87aa-464b-971a-d93c0da8e219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5744c28-5927-4597-9efd-b978fa60f5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c00085-b7d1-4f49-94a5-86d79f60cfce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651dae34-470a-4f5d-ae80-7b2345e175c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd857fe5-6448-4c50-8dc2-2bdf27c7f273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388fa872-7f98-4e92-b8ad-cb9080f05c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9de55f-c482-4efd-9ce2-651df0c46365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3101858-599e-4f67-aaf7-dc69ceef4502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baed864-6155-43fa-8993-c23b5fa1ec41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9147b64c-0377-4f40-8223-6c3e14724392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593e708f-f0ec-4832-be70-5972c7b233a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad2c83-37ca-4f59-adb3-e193d1cdf916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33018e78-d8a3-44f2-9d30-b73715e93b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
